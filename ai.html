<!-- 
  On twitter -> @LoLO_o43
  
  email -> virgosmp.mx@gmail.com

  @CS50
-->


<!DOCTYPE html>

<html lang="en-US">

<head>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.2/dist/css/bootstrap.min.css"
        crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css"
        integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
    <link href="ai.css" rel="stylesheet">
    <title>AI</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
</head>

<body class="hidden">
    <header>
        <div class="centrado" id="onload">
            <div class="lds-ring">
                <div></div>
                <div></div>
                <div></div>
                <div></div>
            </div>
        </div>
        <nav id="nav">
            <div class="nav-containers">
                <a class="navbar-brand" href="https://twitter.com/LoLO_o43">
                    <img src="Pictures/photo_2021-11-08_22-13-20.jpg" alt="Avatar Logo" style="width:40px;"
                        class="rounded-pill">
                </a>
                <div class="links" id="links">
                    <a href="index.html" id="link-home" class="btn-header">Home</a>
                    <a href="form.html" id="link-subscribe" class="btn-header">Subscribe</a>
                </div>
                <div class="icon" id="open">
                    <span>&#9776;</span>
                </div>
            </div>
        </nav>
        <div class="texts">
            <h1>Introduction to AI</h1>
            <h2>Can machines rule the world?</h2>
        </div>
    </header>
    <main>
        <div class="container">
            <figure>
                <h1 class="first-title">Concepts</h1>
                <img src="img/what-is-artificial-intelligence.jpeg" alt="AI">
                <figcaption class="caption">GETTING MACHINES TO SIMULATE HUMAN INTELLIGENCE IS THE FUNDAMENTAL GOAL OF
                    AI.
                </figcaption>
            </figure>

            <h1 class="second-title">How Does Artificial Intelligence Work?</h1>
            <h3>AI Approaches and Concepts</h3>
            <p>Less than a decade after breaking the Nazi encryption machine Enigma and helping the Allied Forces
                win World War II, mathematician Alan Turing changed history a second time with a simple question:
                "Can machines think?"</p>
            <p>Turing's paper <a href="https://www.csee.umbc.edu/courses/471/papers/turing.pdf">"Computing Machinery
                    and Intelligence"</a> (1950), and its subsequent Turing Test,
                established the fundamental goal and vision of artificial intelligence. </p>
            <p>At its core, AI is the branch of computer science that aims to answer Turing's question in the
                affirmative. It is the endeavor to replicate or simulate human intelligence in machines.</p>
            <p>The expansive goal of artificial intelligence has given rise to many questions and debates. So much
                so, that no singular definition of the field is universally accepted. </p>
            <p></p>
            <blockquote>
                <p>Can machines think? – Alan Turing, 1950</p>
            </blockquote>
            <p>The major limitation in defining AI as simply "building machines that are intelligent" is that it
                doesn't actually explain <em>what artificial intelligence is? What makes a machine intelligent?
                </em>AI is an interdisciplinary science with multiple approaches, but advancements in machine
                learning and deep learning are creating a paradigm shift in virtually every sector of the tech
                industry. </p>
            <p>In their groundbreaking textbook <em>Artificial Intelligence: A Modern
                    Approach</em>, authors Stuart
                Russell and Peter Norvig approach the question by unifying their work around the theme of
                intelligent agents in machines. With this in mind, AI is "the study of agents that receive
                percepts
                from the environment and perform actions." (Russel and Norvig viii)</p>
            <p>Norvig and Russell go on to explore four different approaches that have historically defined the
                field of AI: </p>
            <ol>
                <li><strong>Thinking humanly</strong></li>
                <li><strong>Thinking rationally</strong></li>
                <li><strong>Acting humanly </strong></li>
                <li><strong>Acting rationally</strong></li>
            </ol>
            <p>The first two ideas concern thought processes and reasoning, while the others deal with behavior.
                Norvig and Russell focus particularly on rational agents that act to achieve the best outcome,
                noting "all the skills needed for the Turing Test also allow an agent to act rationally." (Russel
                and Norvig 4).</p>
            <p>Patrick Winston, the Ford professor of artificial intelligence and computer science at MIT, <a
                    href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/lecture-videos/lecture-1-introduction-and-scope/"
                    target="_blank">defines AI</a> as "algorithms enabled by constraints, exposed by representations
                that support models targeted at loops that tie thinking, perception and action together."</p>
            <p>While these definitions may seem abstract to the average person, they help focus the field as an area
                of computer science and provide a blueprint for infusing machines and programs with machine learning
                and other subsets of artificial intelligence. </p>
            <p></p>
            <div class="vid">
                <iframe width="854" height="480" src="https://www.youtube.com/embed/UwsrzCVZAb8"
                    title="YouTube video player" frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen></iframe>
                <figcaption class="caption">The Age of A.I</figcaption>
            </div>
            <h1 class="second-title">The Four Types of Artificial Intelligence</h1>
            <h3>Reactive Machines</h3>
            <p>A reactive machine follows the most basic of AI principles and, as its name implies, is capable of only
                using its intelligence to perceive and react to the world in front of it. A reactive machine cannot
                store a memory and as a result cannot rely on past experiences to inform decision making in real-time.
            </p>
            <p>Perceiving the world directly means that reactive machines are designed to complete only a limited number
                of specialized duties. Intentionally narrowing a reactive machine’s worldview is not any sort of
                cost-cutting measure, however, and instead means that this type of AI will be more trustworthy and
                reliable — it will react the same way to the same stimuli every time. </p>
            <p>A famous example of a reactive machine is Deep Blue, which was designed by IBM in the 1990’s as a
                chess-playing supercomputer and defeated international grandmaster Gary Kasparov in a game. Deep Blue
                was only capable of identifying the pieces on a chess board and knowing how each moves based on the
                rules of chess, acknowledging each piece’s present position, and determining what the most logical move
                would be at that moment. The computer was not pursuing future potential moves by its opponent or trying
                to put its own pieces in better position. Every turn was viewed as its own reality, separate from any
                other movement that was made beforehand.
            </p>
            <p>Another example of a game-playing reactive machine is Google’s AlphaGo. AlphaGo is also incapable of
                evaluating future moves but relies on its own neural network to evaluate developments of the present
                game, giving it an edge over Deep Blue in a more complex game. AlphaGo also bested world-class
                competitors of the game, defeating champion Go player Lee Sedol in 2016.</p>
            <p>Though limited in scope and not easily altered, reactive machine artificial intelligence can attain a
                level of complexity, and offers reliability when created to fulfill repeatable tasks.</p>
            <h3>Limited Memory</h3>
            <p>Limited memory artificial intelligence has the ability to store previous data and predictions when
                gathering information and weighing potential decisions — essentially looking into the past for clues on
                what may come next. Limited memory artificial intelligence is more complex and presents greater
                possibilities than reactive machines.</p>
            <p>Limited memory AI is created when a team continuously trains a model in how to analyze and utilize new
                data or an AI environment is built so models can be automatically trained and renewed. When utilizing
                limited memory AI in machine learning, six steps must be followed: Training data must be created, the
                machine learning model must be created, the model must be able to make predictions, the model must be
                able to receive human or environmental feedback, that feedback must be stored as data, and these these
                steps must be reiterated as a cycle.</p>
            <p>There are three major machine learning models that utilize limited memory artificial intelligence:</p>
            <ul dir="ltr">
                <li><strong>Reinforcement learning</strong>, which learns to make better predictions through repeated
                    trial-and-error.</li>
                <li><strong>Long Short Term Memory (LSTM)</strong>, which utilizes past data to help predict the next
                    item in a sequence. LTSMs view more recent information as most important when making predictions and
                    discounts data from further in the past, though still utilizing it to form conclusions</li>
                <li><strong>Evolutionary Generative Adversarial Networks (E-GAN)</strong>, which evolves over time,
                    growing to explore slightly modified paths based off of previous experiences with every new
                    decision. This model is constantly in pursuit of a better path and utilizes simulations and
                    statistics, or chance, to predict outcomes throughout its evolutionary mutation cycle.</li>
            </ul>
            <p dir="ltr"> </p>
            <h3>Theory of Mind</h3>
            <p>Theory of Mind is just that — theoretical. We have not yet achieved the technological and scientific
                capabilities necessary to reach this next level of artificial intelligence. </p>
            <p>The concept is based on the psychological premise of understanding that other living things have thoughts
                and emotions that affect the behavior of one’s self. In terms of AI machines, this would mean that AI
                could comprehend how humans, animals and other machines feel and make decisions through self-reflection
                and determination, and then will utilize that information to make decisions of their own. Essentially,
                machines would have to be able to grasp and process the concept of “mind,” the fluctuations of emotions
                in decision making and a litany of other psychological concepts in real time, creating a two-way
                relationship between people and artificial intelligence.</p>

            <div class="vid">
                <iframe width="854" height="480" src="https://www.youtube.com/embed/DHyUYg8X31c"
                    title="YouTube video player" frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen></iframe>
                <figcaption class="caption">
                    Do robots deserve rights? What if the machines recognize themselves as conscious? By Kurzgesagt – In
                    a
                    Nutshell</figcaption>
            </div>
            <h3>Self-awareness</h3>
            <p>Once Theory of Mind can be established in artificial intelligence, sometime well into the future, the
                final step will be for AI to become self-aware. This kind of artificial intelligence possesses
                human-level consciousness and understands its own existence in the world, as well as the presence and
                emotional state of others. It would be able to understand what others may need based on not just what
                they communicate to them but how they communicate it.</p>
            <p>Self-awareness in artificial intelligence relies both on human researchers understanding the premise of
                consciousness and then learning how to replicate that so it can be built into machines.</p>
            <figure>
                <h1 class="first-title">USES, EXAMPLES + APPLICATIONS</h1>
                <img src="img/artificial-intelligence-uses-examples.jpeg" alt="AI">
                <figcaption class="caption">AI HAS MANY USES. EXAMPLES INCLUDE EVERYTHING FROM AMAZON ALEXA TO
                    SELF-DRIVING CARS.
                </figcaption>
            </figure>
            <h1 class="second-title">How is AI Used? </h1>
            <p>While addressing a crowd at the Japan AI Experience in 2017, DataRobot CEO Jeremy Achin began his speech
                by offering the following definition of how AI is used today:</p>
            <p>"AI is a computer system able to perform tasks that ordinarily require human intelligence... Many of
                these artificial intelligence systems are powered by machine learning, some of them are powered by deep
                learning and some of them are powered by very boring things like rules."</p>
            <p>Artificial intelligence generally falls under two broad categories: </p>
            <ul>
                <li><strong>Narrow AI:</strong> Sometimes referred to as "Weak AI," this kind of artificial intelligence
                    operates within a limited context and is a simulation of human intelligence. Narrow AI is often
                    focused on performing a single task extremely well and while these machines may seem intelligent,
                    they are operating under far more constraints and limitations than even the most basic human
                    intelligence. <br />
                </li>
                <li><strong>Artificial General Intelligence (AGI)</strong>: AGI, sometimes referred to as "Strong AI,"
                    is the kind of artificial intelligence we see in the movies, like the robots from <em>Westworld</em>
                    or Data from <em>Star Trek: The Next Generation</em>. AGI is a machine with general intelligence
                    and, much like a human being, it can apply that intelligence to solve any problem. </li>
            </ul>
            <h1 class="second-title">Narrow Artificial Intelligence</h1>
            <p>Narrow AI is all around us and is easily the most successful realization of artificial intelligence to
                date. With its focus on performing specific tasks, Narrow AI has experienced numerous breakthroughs in
                the last decade that have had "significant societal benefits and have contributed to the economic
                vitality of the nation," according to "Preparing for the Future of Artificial Intelligence," a 2016
                report released by the Obama Administration. </p>
            <p>A few examples of Narrow AI include: </p>
            <ul>
                <li>Google search</li>
                <li>Image recognition software</li>
                <li>Siri, Alexa and other personal assistants</li>
                <li>Self-driving cars</li>
                <li>IBM's Watson </li>
            </ul>
            <h2>Machine Learning &amp; Deep Learning </h2>
            <p>Much of Narrow AI is powered by breakthroughs in machine learning and deep learning. Understanding the
                difference between artificial intelligence, machine learning and deep learning can be confusing. Venture
                capitalist Frank Chen provides a good overview of how to distinguish between them, noting: </p>
            <blockquote>
                <p>"Artificial intelligence is a set of algorithms and intelligence to try to mimic human intelligence.
                    Machine learning is one of them, and deep learning is one of those machine learning techniques."
                </p>
            </blockquote>
            <p>Simply put, machine learning feeds a computer data and uses statistical techniques to help it "learn" how
                to get progressively better at a task, without having been specifically programmed for that task,
                eliminating the need for millions of lines of written code. Machine learning consists of both supervised
                learning (using labeled data sets) and unsupervised learning (using unlabeled data sets). </p>
            <p>Deep learning is a type of machine learning that runs inputs through a biologically-inspired neural
                network architecture. The neural networks contain a number of hidden layers through which the data is
                processed, allowing the machine to go "deep" in its learning, making connections and weighting input for
                the best results.</p>
            <h1 class="second-title">Artificial General Intelligence</h1>
            <p>The creation of a machine with human-level intelligence that can be applied to any task is the Holy Grail
                for many AI researchers, but the quest for AGI has been fraught with difficulty. </p>
            <p>The search for a "universal algorithm for learning and acting in any environment," (Russel and Norvig 27)
                isn't new, but time hasn't eased the difficulty of essentially creating a machine with a full set of
                cognitive abilities. </p>
            <p>AGI has long been the muse of dystopian science fiction, in which super-intelligent robots overrun
                humanity, but experts agree it's not something we need to worry about <a
                    href="https://obamawhitehouse.archives.gov/sites/default/files/whitehouse_files/microsites/ostp/NSTC/preparing_for_the_future_of_ai.pdf"
                    target="_blank">anytime soon</a>.</p>
            <figure>
                <h1 class="first-title">History</h1>
                <img src="img/history-of-ai.jpeg" alt="AI">
                <figcaption class="caption">THE HISTORY OF ARTIFICIAL INTELLIGENCE IS LONG AND ROBUST, GOING BACK TO THE
                    1940S.
                </figcaption>
            </figure>
            <h1 class="second-title">A Brief History of Artificial Intelligence</h1>
            <p>Intelligent robots and artificial beings first appeared in the ancient Greek myths of Antiquity.
                Aristotle's development of syllogism and its use of deductive reasoning was a key moment in mankind's
                quest to understand its own intelligence. While the roots are long and deep, the history of artificial
                intelligence as we think of it today spans less than a century. The following is a quick look at some of
                the most important events in AI. </p>

            <h3><strong>1940s</strong></h3>

            <ul>
                <li>(1943) Warren McCullough and Walter Pitts publish "A Logical Calculus of Ideas Immanent in Nervous
                    Activity." The paper proposed the first mathematical model for building a neural network. </li>
                <li>(1949) In his book <em>The Organization of Behavior: A Neuropsychological Theory, </em>Donald Hebb
                    proposes the theory that neural pathways are created from experiences and that connections between
                    neurons become stronger the more frequently they're used. Hebbian learning continues to be an
                    important model in AI.</li>
            </ul>
            <h3><strong>1950s</strong></h3>

            <ul>
                <li>(1950) Alan Turing publishes "Computing Machinery and Intelligence, proposing what is now known as
                    the Turing Test, a method for determining if a machine is intelligent. </li>
                <li>(1950) Harvard undergraduates Marvin Minsky and Dean Edmonds build SNARC, the first neural network
                    computer.</li>
                <li>(1950) Claude Shannon publishes the paper "Programming a Computer for Playing Chess."</li>
                <li>(1950) Isaac Asimov publishes the "Three Laws of Robotics." </li>
                <li>(1952) Arthur Samuel develops a self-learning program to play checkers. </li>
                <li>(1954) The Georgetown-IBM machine translation experiment automatically translates 60 carefully
                    selected Russian sentences into English. </li>
                <li>(1956) The phrase artificial intelligence is coined at the "Dartmouth Summer Research Project on
                    Artificial Intelligence." Led by John McCarthy, the conference, which defined the scope and goals of
                    AI, is widely considered to be the birth of artificial intelligence as we know it today. </li>
                <li>(1956) Allen Newell and Herbert Simon demonstrate Logic Theorist (LT), the first reasoning program.
                </li>
                <li>(1958) John McCarthy develops the AI programming language Lisp and publishes the paper "Programs
                    with Common Sense." The paper proposed the hypothetical Advice Taker, a complete AI system with the
                    ability to learn from experience as effectively as humans do. </li>
                <li>(1959) Allen Newell, Herbert Simon and J.C. Shaw develop the General Problem Solver (GPS), a program
                    designed to imitate human problem-solving. </li>
                <li>(1959) Herbert Gelernter develops the Geometry Theorem Prover program.</li>
                <li>(1959) Arthur Samuel coins the term machine learning while at IBM.</li>
                <li>(1959) John McCarthy and Marvin Minsky founded the MIT Artificial Intelligence Project.</li>
            </ul>
            <h3><strong>1960s</strong></h3>

            <ul>
                <li>(1963) John McCarthy starts the AI Lab at Stanford.</li>
                <li>(1966) The Automatic Language Processing Advisory Committee (ALPAC) report by the U.S. government
                    details the lack of progress in machine translations research, a major Cold War initiative with the
                    promise of automatic and instantaneous translation of Russian. The ALPAC report leads to the
                    cancellation of all government-funded MT projects. </li>
                <li>(1969) The first successful expert systems are developed in DENDRAL, a XX program, and MYCIN,
                    designed to diagnose blood infections, are created at Stanford.</li>
            </ul>
            <h3><strong>1970s</strong></h3>

            <ul>
                <li>(1972) The logic programming language PROLOG is created.</li>
                <li>(1973) The "Lighthill Report," detailing the disappointments in AI research, is released by the
                    British government and leads to severe cuts in funding for artificial intelligence projects. </li>
                <li>(1974-1980) Frustration with the progress of AI development leads to major DARPA cutbacks in
                    academic grants. Combined with the earlier ALPAC report and the previous year's "Lighthill Report,"
                    artificial intelligence funding dries up and research stalls. This period is known as the "First AI
                    Winter." </li>
            </ul>
            <h3><strong>1980s</strong></h3>

            <ul>
                <li>(1980) Digital Equipment Corporations develops R1 (also known as XCON), the first successful
                    commercial expert system. Designed to configure orders for new computer systems, R1 kicks off an
                    investment boom in expert systems that will last for much of the decade, effectively ending the
                    first "AI Winter."</li>
                <li>(1982) Japan's Ministry of International Trade and Industry launches the ambitious Fifth Generation
                    Computer Systems project. The goal of FGCS is to develop supercomputer-like performance and a
                    platform for AI development.</li>
                <li>(1983) In response to Japan's FGCS, the U.S. government launches the Strategic Computing Initiative
                    to provide DARPA funded research in advanced computing and artificial intelligence. </li>
                <li>(1985) Companies are spending more than a billion dollars a year on expert systems and an entire
                    industry known as the Lisp machine market springs up to support them. Companies like Symbolics and
                    Lisp Machines Inc. build specialized computers to run on the AI programming language Lisp. </li>
                <li>(1987-1993) As computing technology improved, cheaper alternatives emerged and the Lisp machine
                    market collapsed in 1987, ushering in the "Second AI Winter." During this period, expert systems
                    proved too expensive to maintain and update, eventually falling out of favor.</li>
            </ul>
            <h3><strong>1990s</strong></h3>

            <ul>
                <li>(1991) U.S. forces deploy DART, an automated logistics planning and scheduling tool, during the Gulf
                    War.</li>
                <li>(1992) Japan terminates the FGCS project in 1992, citing failure in meeting the ambitious goals
                    outlined a decade earlier.</li>
                <li>(1993) DARPA ends the Strategic Computing Initiative in 1993 after spending nearly $1 billion and
                    falling far short of expectations. </li>
                <li>(1997) IBM's Deep Blue beats world chess champion Gary Kasparov</li>
            </ul>
            <h3><strong>2000s</strong></h3>

            <ul>
                <li>(2005) STANLEY, a self-driving car, wins the DARPA Grand Challenge.</li>
                <li>(2005) The U.S. military begins investing in autonomous robots like Boston Dynamics' "Big Dog" and
                    iRobot's "PackBot."</li>
                <li>(2008) Google makes breakthroughs in speech recognition and introduces the feature in its iPhone
                    app. </li>
            </ul>
            <h3><strong>2010-2014</strong></h3>

            <ul>
                <li>(2011) <a
                        href="https://builtin.com/artificial-intelligence/ibms-watson-finds-new-challenge-construction"
                        target="_blank">IBM's Watson</a> trounces the competition on <em>Jeopardy!. </em></li>
                <li>(2011) Apple releases Siri, an AI-powered virtual assistant through its iOS operating
                    system.<strong> </strong></li>
                <li>(2012) Andrew Ng, founder of the Google Brain Deep Learning project, feeds a neural network using
                    deep learning algorithms 10 million YouTube videos as a training set. The neural network learned to
                    recognize a cat without being told what a cat is, ushering in the breakthrough era for neural
                    networks and deep learning funding.</li>
                <li>(2014) Google makes the first <a href="https://builtin.com/transportation-tech"
                        target="_blank">self-driving car</a> to pass a state driving test. </li>
                <li>(2014) Amazon's Alexa, a virtual home is released </li>
            </ul>
            <h3><strong>2015-2021</strong></h3>

            <ul>
                <li>(2016) Google DeepMind's <a href="https://builtin.com/artificial-intelligence/ai-games"
                        target="_blank">AlphaGo</a> defeats world champion Go player Lee Sedol. The complexity of the
                    ancient Chinese game was seen as a major hurdle to clear in AI.</li>
                <li>(2016) The first "robot citizen", a humanoid robot named Sophia, is created by Hanson Robotics and
                    is capable of facial recognition, verbal communication and facial expression.</li>
                <li>(2018) Google releases natural language processing engine <a
                        href="https://builtin.com/data-science/using-bert-battle-job-scams" target="_blank">BERT</a>,
                    reducing barriers in translation and understanding by machine learning applications.</li>
                <li>(2018) <a href="https://builtin.com/design-ux/driverless-car-trust-design" target="_blank">Waymo</a>
                    launches its Waymo One service, allowing users throughout the Phoenix metropolitan area to request a
                    pick-up from one of the company's self-driving vehicles.</li>
                <li>(2020) Baidu releases its LinearFold AI algorithm to scientific and medical teams working to develop
                    a vaccine during the early stages of the SARS-CoV-2 pandemic. The algorithm is able to predict the
                    RNA sequence of the virus in just 27 seconds, 120 times faster than other methods.</li>
            </ul>
            <p> </p>
        </div>
    </main>
    <footer id="contact">
        <div class="footer">
            <div class="icons">
                <a href="https://www.youtube.com/">
                    <i class="fab fa-youtube"></i>
                </a>
                <a href="https://www.facebook.com/">
                    <i class="fab fa-facebook-square"></i>
                </a>
                <a href="https://github.com/San-43">
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <p>Thanks <a href="https://en.wikipedia.org/wiki/Ada_Lovelace"><strong>Ada Lovelace!</strong></a></p>
        </div>
    </footer>
    <script src="https://code.jquery.com/jquery-3.6.0.js"
        integrity="sha256-H+K7U5CnXl1h5ywQfKtSj8PCmoN9aaq30gDh27Xc0jk=" crossorigin="anonymous"></script>
    <script src="Js/ai.js"></script>
</body>

</html>